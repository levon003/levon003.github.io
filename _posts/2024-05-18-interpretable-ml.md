---
layout: post
title:  "Interpretable machine learning with scoring models"
date:   2024-05-18
tags: research short
excerpt: "Cynthia Rudin's research on scoring models."
---
On the subject of interpretable machine learning, I always recommend Cynthia Rudin's work first.

Start with her excellent talk ["Scoring Systems: At the Extreme of Interpretable Machine Learning"](https://www.youtube.com/watch?v=2vyPW3BL2c8&t=160s) (2022) and some of the papers and packages it references.

Her 2021 paper on grand challenges in interpretable machine learning is still worth reading: ["Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges"](https://arxiv.org/abs/2103.11251).

A few related GitHub repositories:

- [fastSparse](https://github.com/interpretml/fastSparse) (R package)
- [Generalized Optimal Sparse Decision Trees](https://github.com/ubc-systopia/gosdt-guesses) (Python package)
- [FasterRisk](https://github.com/interpretml/FasterRisk) (Python package for sparse linear models with integer coefficients)
- [Pycorels](https://github.com/corels/pycorels) (Python package, not maintained)

Zachary Lipton's ["The Mythos of Model Interpretability"](https://arxiv.org/abs/1606.03490) was also hugely influential on my thinking about interpretability.
